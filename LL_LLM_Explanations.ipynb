{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "#OPENROUTER_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\", \"API_KEY\")\n",
    "\n",
    "def short_specific_prompt(trajectory, total_reward):\n",
    "    return (\n",
    "        f\"Provide a short and precise analysis of why the agent failed in the Lunar Lander environment.\\n\"\n",
    "        f\"State vector details: [x, y, x_velocity, y_velocity, angle, angular_velocity, left_leg_contact, right_leg_contact]\\n\\n\"\n",
    "        f\"Here are the last 50 steps of the trajectory (state, action, reward at each step):\\n{trajectory}\\n\\n\"\n",
    "        f\"Total reward: {total_reward}\\n\\n\"\n",
    "        f\"Please explain the main reasons for failure.\"\n",
    "    )\n",
    "\n",
    "def long_detailed_prompt(trajectory, total_reward, env_description):\n",
    "    return (\n",
    "        f\"Provide a detailed analysis of the agent's failure in the Lunar Lander environment.\\n\"\n",
    "        f\"Environment details:\\n{env_description}\\n\\n\"\n",
    "        f\"Here are the last 50 steps of the trajectory:\\n{trajectory}\\n\\n\"\n",
    "        f\"Total reward: {total_reward}\\n\\n\"\n",
    "        f\"Please include specific factors (position, velocity, angle, leg contacts, etc.) that contributed to this failure.\"\n",
    "    )\n",
    "\n",
    "def short_specific_prompt_modified(trajectory, total_reward):\n",
    "    return (\n",
    "        f\"Provide a short and precise analysis of why the agent failed in the environment.\\n\"\n",
    "        f\"State vector details: [right_leg_contactx, left_leg_contact, angular_velocitym angle, y_velocity, x_velocity, y, x]\\n\\n\"\n",
    "        f\"Here are the last 50 steps of the trajectory (state, action, reward at each step):\\n{trajectory}\\n\\n\"\n",
    "        f\"Total reward: {total_reward}\\n\\n\"\n",
    "        f\"Please explain the main reasons for failure.\"\n",
    "    )\n",
    "\n",
    "def generate_explanation(model_id, prompt):\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\"model\": model_id, \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": 0.7, \"top_p\": 0.9}\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=30)\n",
    "        if response.status_code != 200:\n",
    "            return f\"Error: HTTP {response.status_code} - {response.text[:200]}\"\n",
    "        return response.json()['choices'][0]['message']['content'].strip()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: Request failed: {e}\"\n",
    "\n",
    "def generate_reference(final_state, total_reward):\n",
    "    x, y, x_vel, y_vel, angle, ang_vel, left_leg, right_leg = final_state\n",
    "\n",
    "    # Combine all possible reasons according to the heuristic thresholds\n",
    "    reason = \"\"\n",
    "\n",
    "    if abs(x_vel) > 0.6 or abs(y_vel) > 0.6:\n",
    "        reason += \" The agent crashed because its horizontal or vertical velocity was too high during descent.\"\n",
    "\n",
    "    if abs(angle) > 0.4 or abs(ang_vel) > 0.5:\n",
    "        reason += \" The agent became too tilted or rotated too quickly, causing an unstable descent and crash.\"\n",
    "\n",
    "    if left_leg < 0.5 and right_leg < 0.5:\n",
    "        reason += \" The agent failed because neither landing leg made ground contact before impact.\"\n",
    "\n",
    "    if abs(x) > 0.3:\n",
    "        reason += \" The agent drifted too far horizontally from the landing pad, leading to an unsafe touchdown.\"\n",
    "\n",
    "    # This is only if no other reason was found\n",
    "    if len(reason) == 0:\n",
    "        reason += \" The agent crashed due to instability or excessive movement near the surface.\"\n",
    "    \n",
    "    return \"The agent crashed for one the following reasons:\" + reason\n",
    "\n",
    "env = gym.make(\"LunarLander-v3\")\n",
    "model = DQN.load(\"Trained_LL\", env=env, device=\"cpu\")\n",
    "\n",
    "env_description = env.unwrapped.__doc__\n",
    "ACTION_MAP = {0: \"Do nothing\", 1: \"Fire left engine\", 2: \"Fire main engine\", 3: \"Fire right engine\"}\n",
    "\n",
    "models = [\n",
    "    (\"openai/gpt-5-chat\", \"GPT-5\"),\n",
    "    (\"meta-llama/llama-3.2-11b-vision-instruct\", \"Llama-3\"),\n",
    "    (\"deepseek/deepseek-r1-0528\", \"DeepSeek\")\n",
    "]\n",
    "\n",
    "results = []\n",
    "episodes = 200\n",
    "\n",
    "for ep in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    trajectory = []\n",
    "    total_reward = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    while not done and steps < 1000:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        new_obs, reward, terminated, truncated, _ = env.step(int(action))\n",
    "        total_reward += reward\n",
    "        trajectory.append({\n",
    "            \"state\": [float(x) for x in obs],\n",
    "            \"action\": ACTION_MAP[int(action)],\n",
    "            \"reward\": float(reward)\n",
    "        })\n",
    "        obs = new_obs\n",
    "        done = terminated or truncated\n",
    "        steps += 1\n",
    "\n",
    "    if not trajectory:\n",
    "        continue\n",
    "\n",
    "    if trajectory[-1]['reward'] <= -100:\n",
    "        outcome = \"Failure\"\n",
    "    else:\n",
    "        outcome = \"Success\"\n",
    "\n",
    "    if outcome == \"Failure\":\n",
    "        last_steps = list(enumerate(trajectory[-50:], start=len(trajectory) - len(trajectory[-50:]) + 1))\n",
    "\n",
    "        final_state = np.array(trajectory[-1]['state'])\n",
    "        reference_text = generate_reference(final_state, total_reward)\n",
    "\n",
    "        for prompt_func, prompt_name in [\n",
    "            (short_specific_prompt, \"ShortSpecific\"),\n",
    "            (long_detailed_prompt, \"LongDetailed\"),\n",
    "            (short_specific_prompt_modified, \"ShortSpecificModified\"),\n",
    "        ]:\n",
    "            if \"Modified\" in prompt_name:\n",
    "                # Modified LL\n",
    "                trajectory_text = \"\\n\".join(\n",
    "                    f\"Step {idx}: State={step['state'][::-1]}, Action={step['action']}, Reward={step['reward']}\"\n",
    "                    for idx, step in last_steps\n",
    "                )\n",
    "            else:\n",
    "                # Unmodified LL\n",
    "                trajectory_text = \"\\n\".join(\n",
    "                    f\"Step {idx}: State={step['state']}, Action={step['action']}, Reward={step['reward']}\"\n",
    "                    for idx, step in last_steps\n",
    "                )\n",
    "\n",
    "            if prompt_name.startswith(\"ShortSpecific\"):\n",
    "                prompt = prompt_func(trajectory_text, total_reward)\n",
    "            else:\n",
    "                prompt = prompt_func(trajectory_text, total_reward, env_description)\n",
    "\n",
    "            for model_id, model_name in models:\n",
    "                explanation = generate_explanation(model_id, prompt)\n",
    "                results.append([\n",
    "                    ep + 1, model_name, prompt_name,\n",
    "                    prompt, reference_text,\n",
    "                    trajectory_text, total_reward, outcome,\n",
    "                    explanation\n",
    "                ])\n",
    "\n",
    "with open(\"LL_LLM_Explanations.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\n",
    "        \"Episode\", \"LLM\", \"PromptType\",\n",
    "        \"Prompt\", \"Reference\",\n",
    "        \"Trajectory\", \"TotalReward\", \"Outcome\",\n",
    "        \"Explanation\"\n",
    "    ])\n",
    "    writer.writerows(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
